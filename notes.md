# Notes
Things researched while planning/creating site

- [Steps for planning a new website](https://www.hallaminternet.com/9-steps-for-planning-a-new-website/)
    - Helped with the initial planning outline
    - Considered what I want on the site
    - Notes on why a user would be on the site
        - Why they would want
        - What I would want them to leave with
    - Content inventory for redevelopment
        - Get an idea of what is currently there
        - Make cuts
        - Know what is lacking
    - Card Sorting
        - Grouping content and categories
        - Potential/exiting users could be beneficial
    - Sitemap creation/completion
        - Putting all the information together
        - User testing to check if the sitemap makes sense to user
            - Tree testing
    - Call to Action
        - What will a user do on the site
        - The most important take away from the site
    - Chooseing content management system to use (Framework, stack... what will it be built from)
        - Svelte, JS, TS, Firebase hosting, Firestore DB
        - Svelte: To learn through building an app
        - JS, TS: Currently comfortable with these.
        - Snowpack: To learn and understand more. Get a better understanding of what a bundler does. Comparing experiences with different methods will help me understand the bigger picture of what a bundler can do. How they work, what is typical, what is specifically for one bundler over another.
        - Firebase: Potential for growth with the other features avaliable. With a built site, it would be easy to see how other features work, why they would be used, and also to the potential new additions Google will inevitably have.
            - Firebase hosting: Loads faster than Heroku. Easy setup. Domain is with GoogleDomains
            - FireStore: To learn through building an app.
- [SEO tips](https://www.hallaminternet.com/web-design-nottingham-4-seo-tips/) *Rabbit Hole Article*
    - Not necessarily important to my particular site. Neat to read though, and learnt some stuff
        - Why website structure matters
        - Importance of keywords
        - Impotance of SEO considerations when site is being built
        - Potential problems for site redevelopment
        - 301 Redirects for SE to know where old content has been moved if a site is rebuilt
    - no index meta attribute - SE will not include those pages in a search result
    - New site structure, how to communicate it to a search engine

> Robots.txt – Creating a robots.txt file allows you to specify any site directories or pages that you don’t want Google to index or crawl.

First time I've read anything about Robots.txt. I had no idea what it was, why it existed... enlightening

## Resources/Tools
- [Screaming Frog](https://www.screamingfrog.co.uk/seo-spider/#spider-features): SEO Tool

> Free version features: Find Broken Links, Errors & Redirects. Analyse Page Titles & Meta Data. Review Meta Robots & Directives. Audit hreflang Attributes. Discover Exact Duplicate Pages. Generate XML Sitemaps. Site Visualisations.

- [Optimal Workshop](https://www.optimalworkshop.com/): Tools to help research user experiences

> Free version features: No time limits on free plan. Create an unlimited number of studies. Collect 10 responses per study. Free card sorting: 30 cards using OptimalSort. Free tree testing: 3 tasks using Treejack. Free first click tests: 3 tasks using Chalkmark. Free survey forms: using Questions. Qualitative research using Reframer.

- [Slick Plan](https://slickplan.com/): website planning system

> Free version features: One sitemap. Basic functionality. A single user.
